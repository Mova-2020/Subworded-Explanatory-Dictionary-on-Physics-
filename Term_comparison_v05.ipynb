{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDaIshKMyZmoqcCaVZA018",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mova-2020/Subworded-Explanatory-Dictionary-on-Physics-/blob/main/Term_comparison_v05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "\n",
        "!pip install sentence-transformers\n",
        "!pip install nltk==3.8.1\n",
        "!pip install spacy\n",
        "!python -m spacy download uk_core_news_sm"
      ],
      "metadata": {
        "id": "JDxls0NdXTSn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e90e0831-9b16-4eb3-b969-aa95ccc277c6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.3.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.47.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.27.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.12.14)\n",
            "Requirement already satisfied: nltk==3.8.1 in /usr/local/lib/python3.11/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk==3.8.1) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk==3.8.1) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk==3.8.1) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk==3.8.1) (4.67.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.10.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.12.14)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting uk-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/uk_core_news_sm-3.7.0/uk_core_news_sm-3.7.0-py3-none-any.whl (14.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from uk-core-news-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: pymorphy3>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from uk-core-news-sm==3.7.0) (2.0.2)\n",
            "Requirement already satisfied: pymorphy3-dicts-uk in /usr/local/lib/python3.11/dist-packages (from uk-core-news-sm==3.7.0) (2.4.1.1.1663094765)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from pymorphy3>=1.0.0->uk-core-news-sm==3.7.0) (0.7.2)\n",
            "Requirement already satisfied: pymorphy3-dicts-ru in /usr/local/lib/python3.11/dist-packages (from pymorphy3>=1.0.0->uk-core-news-sm==3.7.0) (2.4.417150.4580142)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (2.5.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (2.10.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (2024.12.14)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (1.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->uk-core-news-sm==3.7.0) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('uk_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer('all-mpnet-base-v2')\n",
        "# Load a pre-trained sentence transformer model"
      ],
      "metadata": {
        "id": "OvWF31wBXgIS"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper functions for each criterion"
      ],
      "metadata": {
        "id": "-Ogx5r1nLy_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Exactness (cosine similarity between term and definition)\n",
        "def exactness(term, definition):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform([term, definition])\n",
        "    cosine_sim = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])[0][0]\n",
        "    return cosine_sim"
      ],
      "metadata": {
        "id": "rNTk9_I2L3dt"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Essentiality (ratio of largest and second-largest entailment degrees from definition)\n",
        "def essentiality(entailments):\n",
        "    largest = max(entailments)\n",
        "    second_largest = sorted(entailments, reverse=True)[1]\n",
        "    return largest / second_largest if second_largest != 0 else float('inf')"
      ],
      "metadata": {
        "id": "AqNL1gJGMLy1"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Plainness (ratio of subwords in the term and its definition)\n",
        "def plainness(term, definition):\n",
        "    term_subwords = set(term.split())\n",
        "    definition_subwords = set(definition.split())\n",
        "    common_subwords = term_subwords.intersection(definition_subwords)\n",
        "    return len(common_subwords) / len(term_subwords) if term_subwords else 0"
      ],
      "metadata": {
        "id": "iahk1ljrMNGs"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Derivativity (favorable word structure and ending)\n",
        "def derivativity(term):\n",
        "    bad_endings = (\"nnja\", \"tja\", \"ння\", \"тя\")\n",
        "    num_words = len(term.replace('-', ' ').split())  # Рахуємо слова, розділені пробілами або дефісами\n",
        "\n",
        "    if term.endswith(bad_endings):\n",
        "        return 0  # Bad derivation if ending in \"nnja\", \"tja\", \"ння\", \"тя\"\n",
        "\n",
        "    if num_words == 1:\n",
        "        return 1  # Просте слово без закінчень \"nnja\", \"tja\", \"ння\", \"тя\"\n",
        "    elif num_words == 2:\n",
        "        return 0.5  # Два слова без закінчень \"nnja\", \"tja\", \"ння\", \"тя\"\n",
        "    else:\n",
        "        return 0  # Три і більше слова\n"
      ],
      "metadata": {
        "id": "T4J6QTOzMaWU"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Good sound (phonotactic rules compliance)\n",
        "def good_sound(term):\n",
        "    bad_clusters = [\"ngh\", \"shr\", \"zhr\", \"r r\", \"stj st\", \"st st\", \"нг\", \"шр\", \"жр\", \"р р\", \"сть ст\", \"ст ст\"]\n",
        "    if any(cluster in term for cluster in bad_clusters):\n",
        "        return 0\n",
        "    # Розбиваємо термін на слова\n",
        "    words = term.split()\n",
        "\n",
        "    # Перевіряємо наявність нових кластерів між словами\n",
        "    for i in range(len(words) - 1):\n",
        "        if words[i].endswith(\"р \") and words[i+1].startswith(\"р\"):\n",
        "            return 0\n",
        "        if words[i].endswith(\"сть \") and words[i+1].startswith(\"ст\"):\n",
        "            return 0\n",
        "    return 1 # Return 1 if no bad clusters are found"
      ],
      "metadata": {
        "id": "5VplE1ZzMet8"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Systemic feature (existence of hypernyms or hyponyms in the dictionary)\n",
        "def systemic_feature(term, dictionary_entries):\n",
        "    related_entries = [entry for entry in dictionary_entries if term in entry]\n",
        "    return len(related_entries)"
      ],
      "metadata": {
        "id": "DJruXvMyMkH8"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Organicity (inverse of maximum subword length)\n",
        "def organicity(term):\n",
        "    subwords = term.split()\n",
        "    max_length = max(len(subword) for subword in subwords)\n",
        "    return 1 / max_length if max_length != 0 else 0"
      ],
      "metadata": {
        "id": "_khWN1OnMoC0"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Compatibility (syntactic valence of the term)\n",
        "def compatibility(term, term_valences):\n",
        "    return term_valences.get(term, 0)  # Placeholder for valence calculation"
      ],
      "metadata": {
        "id": "MKk5cZCeMq4d"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Unambiguity (inverse of number of definitions for the term)\n",
        "def unambiguity(definitions_count):\n",
        "    return 1 / definitions_count if definitions_count != 0 else 0"
      ],
      "metadata": {
        "id": "Kg-iZwCKMwM1"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Nominativity (absence of descriptive structures with prepositions)\n",
        "def nominativity(term):\n",
        "    prepositions = [\"z \", \"zi \", \"iz \", \"za \", \"proty \", \"po \", \"vid \", \"do \", \"з \", \"зі \", \"із \", \"за \", \"проти \", \"по \", \"від \", \"до \"]\n",
        "    n_conj = sum(1 for prep in prepositions if prep in term)  # Count prepositions in the term\n",
        "    return 1 / (1 + n_conj)  # Calculate nominativity according to the formula"
      ],
      "metadata": {
        "id": "NDXcCHmjM3rW"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Brevity (inverse number of symbols in the term)\n",
        "def brevity(term):\n",
        "    return 1 / len(term) if len(term) != 0 else 0"
      ],
      "metadata": {
        "id": "5ghLkaQcM4cF"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data input"
      ],
      "metadata": {
        "id": "a8bv88_zNOln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_terms_from_user():\n",
        "    # Просить користувача ввести терміни та їх означення для порівняння\n",
        "    while True:\n",
        "        try:\n",
        "            num_terms_input = input(\"Введіть кількість термінів для порівняння (за замовчуванням 2): \")\n",
        "            num_terms = int(num_terms_input) if num_terms_input else 2  # Use 2 as default if input is empty\n",
        "            break\n",
        "        except ValueError:\n",
        "            print(\"Неправильний ввід. Будь ласка, введіть число.\")\n",
        "\n",
        "    terms_and_definitions = {}  # Using a dictionary to store terms and definitions\n",
        "    for i in range(num_terms):\n",
        "        term = input(f\"Введіть термін {i + 1}: \")\n",
        "        definition = input(f\"Введіть означення для терміна '{term}': \")\n",
        "        terms_and_definitions[term] = {'definition': definition, 'systemic_feature': 0}  # Store term, definition, and initialize systemic_feature\n",
        "\n",
        "    # Now ask about systemic features after getting all terms and definitions\n",
        "    for term, data in terms_and_definitions.items():\n",
        "        while True:\n",
        "            systemic_input = input(f\"Чи наявні в терміносистемі гіпероніми або гіпоніми до терміна '{term}'?\\nВведіть '1', якщо такі є, або '0', якщо таких немає: \")\n",
        "            if systemic_input in [\"1\", \"0\"]:\n",
        "                data['systemic_feature'] = int(systemic_input) # Update systemic_feature in the dictionary\n",
        "                break\n",
        "            else:\n",
        "                print(\"Неправильний ввід. Будь ласка, введіть 1 або 0.\")\n",
        "\n",
        "    return terms_and_definitions  # Return the dictionary"
      ],
      "metadata": {
        "id": "YzXlt7b0NSNc"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scores"
      ],
      "metadata": {
        "id": "mkn_oA8123Kb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_scores_for_terms(terms_and_definitions):\n",
        "    # Обчислює бали для кожного терміна\n",
        "\n",
        "    # Load Ukrainian spaCy model\n",
        "    nlp = spacy.load(\"uk_core_news_sm\")\n",
        "\n",
        "    # Assign valence (number of POS connections)\n",
        "    term_valences = {}\n",
        "    for term, data in terms_and_definitions.items():\n",
        "        definition = data['definition'] # Access definition from the nested dictionary\n",
        "        # Create a sentence with the term and definition for context\n",
        "        sentence = f\"{term} {definition}\"\n",
        "        doc = nlp(sentence)\n",
        "\n",
        "        # Find the term in the parsed sentence\n",
        "        term_token = next((token for token in doc if token.text == term), None)\n",
        "\n",
        "        if term_token:\n",
        "            # Get POS tags of surrounding words\n",
        "            surrounding_pos = [token.pos_ for token in term_token.children]\n",
        "\n",
        "            # Calculate valence as the number of unique POS tags\n",
        "            valence = len(set(surrounding_pos))\n",
        "        else:\n",
        "            valence = 0  # Default valence if term not found\n",
        "\n",
        "        term_valences[term] = valence\n",
        "\n",
        "    scores = {}\n",
        "    for term, data in terms_and_definitions.items():  # Iterate through the nested dictionary\n",
        "        definition = data[\"definition\"]\n",
        "        systemic_feature_value = data[\"systemic_feature\"]\n",
        "\n",
        "        # Calculate Exactness using cosine similarity\n",
        "        exactness_score = exactness(term, definition)\n",
        "        print(f\"Cosine similarity for '{term}': {exactness_score}\") # Print for debugging\n",
        "\n",
        "        # Essentiality Calculation (placeholder - requires entailment logic)\n",
        "        # Replace this with your actual entailment calculation\n",
        "        entailments = [0.8, 0.6, 0.4]  # Example entailment degrees\n",
        "        essentiality_score = essentiality(entailments)\n",
        "\n",
        "        # Plainness calculation using NLTK\n",
        "        term_subwords = set(ngrams(term, len(\"бозон\"))) # Generate subwords of length 4\n",
        "        definition_subwords = set(ngrams(definition, len(\"бозон\")))\n",
        "        common_subwords = term_subwords.intersection(definition_subwords) # Find common subwords\n",
        "\n",
        "        # Convert ngrams back to strings for plainness calculation\n",
        "        common_subwords_str = {\"\".join(ngram) for ngram in common_subwords}\n",
        "        term_subwords_str = {\"\".join(ngram) for ngram in term_subwords}\n",
        "        plainness_score = len(common_subwords_str) / len(term_subwords_str) if term_subwords_str else 0\n",
        "\n",
        "        print(f\"Common subwords for '{term}': {common_subwords}\")  # Print for debugging\n",
        "\n",
        "        # Initialize scores for the current term\n",
        "        scores_term = {\n",
        "            \"Exactness\": exactness_score,\n",
        "            \"Essentiality\": essentiality_score,\n",
        "            \"Plainness\": plainness_score,\n",
        "            \"Derivativity\": derivativity(term),\n",
        "            \"Good Sound\": good_sound(term),\n",
        "            # Use the populated dictionary\n",
        "            \"Systemic Feature\": systemic_feature_value,  # Access systemic feature value\n",
        "            \"Organicity\": organicity(term),\n",
        "            # Use the populated term_valences\n",
        "            \"Compatibility\": compatibility(term, term_valences),\n",
        "            \"Unambiguity\": 1,  # Replace with actual calculation based on definition count\n",
        "            \"Nominativity\": nominativity(term),  # No prepositionss in the term\n",
        "            \"Brevity\": brevity(term),\n",
        "        }\n",
        "        scores[term] = scores_term\n",
        "        #Assign scores_term to scores dictionary with term as key\n",
        "    return scores\n"
      ],
      "metadata": {
        "id": "osU3_-DU24-k"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparison"
      ],
      "metadata": {
        "id": "PHH2bIZIOuK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "1terms_and_definitions = get_terms_from_user() # Get terms and definitions first\n",
        "scores = calculate_scores_for_terms(terms_and_definitions) # Then calculate scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3ULQw7PTFDG",
        "outputId": "23a4841c-ff49-4b61-bff9-450e46317a2e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Введіть кількість термінів для порівняння (за замовчуванням 2): 4\n",
            "Введіть термін 1: вода\n",
            "Введіть означення для терміна 'вода': Прозора безбарвна рідина, що становить собою найпростішу хімічну сполуку водню з киснем. \n",
            "Введіть термін 2: камінь\n",
            "Введіть означення для терміна 'камінь': Прозора безбарвна рідина, що становить собою найпростішу хімічну сполуку водню з киснем. \n",
            "Введіть термін 3: радість\n",
            "Введіть означення для терміна 'радість': Прозора безбарвна рідина, що становить собою найпростішу хімічну сполуку водню з киснем. \n",
            "Введіть термін 4: бігати\n",
            "Введіть означення для терміна 'бігати': Прозора безбарвна рідина, що становить собою найпростішу хімічну сполуку водню з киснем. \n",
            "Чи наявні в терміносистемі гіпероніми або гіпоніми до терміна 'вода'?\n",
            "Введіть '1', якщо такі є, або '0', якщо таких немає: 1\n",
            "Чи наявні в терміносистемі гіпероніми або гіпоніми до терміна 'камінь'?\n",
            "Введіть '1', якщо такі є, або '0', якщо таких немає: \n",
            "Неправильний ввід. Будь ласка, введіть 1 або 0.\n",
            "Чи наявні в терміносистемі гіпероніми або гіпоніми до терміна 'камінь'?\n",
            "Введіть '1', якщо такі є, або '0', якщо таких немає: 1\n",
            "Чи наявні в терміносистемі гіпероніми або гіпоніми до терміна 'радість'?\n",
            "Введіть '1', якщо такі є, або '0', якщо таких немає: 1\n",
            "Чи наявні в терміносистемі гіпероніми або гіпоніми до терміна 'бігати'?\n",
            "Введіть '1', якщо такі є, або '0', якщо таких немає: 1\n",
            "Cosine similarity for 'вода': 0.0\n",
            "Common subwords for 'вода': set()\n",
            "Cosine similarity for 'камінь': 0.0\n",
            "Common subwords for 'камінь': set()\n",
            "Cosine similarity for 'радість': 0.0\n",
            "Common subwords for 'радість': set()\n",
            "Cosine similarity for 'бігати': 0.0\n",
            "Common subwords for 'бігати': set()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for term, term_scores in scores.items():\n",
        "    print(f\"Бали для терміна '{term}': {term_scores}\")\n",
        "    overall_score = sum(term_scores.values()) / len(term_scores)\n",
        "    print(f\"Загальний бал для терміна '{term}': {overall_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNiom6TDOu1U",
        "outputId": "f142649b-bb4c-42ea-890e-0802623bea8f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Бали для терміна 'вода': {'Exactness': 0.0, 'Essentiality': 1.3333333333333335, 'Plainness': 0, 'Derivativity': 1, 'Good Sound': 1, 'Systemic Feature': 1, 'Organicity': 0.25, 'Compatibility': 1, 'Unambiguity': 1, 'Nominativity': 1.0, 'Brevity': 0.25}\n",
            "Загальний бал для терміна 'вода': 0.7121212121212122\n",
            "Бали для терміна 'камінь': {'Exactness': 0.0, 'Essentiality': 1.3333333333333335, 'Plainness': 0.0, 'Derivativity': 1, 'Good Sound': 1, 'Systemic Feature': 1, 'Organicity': 0.16666666666666666, 'Compatibility': 1, 'Unambiguity': 1, 'Nominativity': 1.0, 'Brevity': 0.16666666666666666}\n",
            "Загальний бал для терміна 'камінь': 0.6969696969696971\n",
            "Бали для терміна 'радість': {'Exactness': 0.0, 'Essentiality': 1.3333333333333335, 'Plainness': 0.0, 'Derivativity': 1, 'Good Sound': 1, 'Systemic Feature': 1, 'Organicity': 0.14285714285714285, 'Compatibility': 3, 'Unambiguity': 1, 'Nominativity': 1.0, 'Brevity': 0.14285714285714285}\n",
            "Загальний бал для терміна 'радість': 0.8744588744588746\n",
            "Бали для терміна 'бігати': {'Exactness': 0.0, 'Essentiality': 1.3333333333333335, 'Plainness': 0.0, 'Derivativity': 1, 'Good Sound': 1, 'Systemic Feature': 1, 'Organicity': 0.16666666666666666, 'Compatibility': 2, 'Unambiguity': 1, 'Nominativity': 1.0, 'Brevity': 0.16666666666666666}\n",
            "Загальний бал для терміна 'бігати': 0.7878787878787878\n"
          ]
        }
      ]
    }
  ]
}